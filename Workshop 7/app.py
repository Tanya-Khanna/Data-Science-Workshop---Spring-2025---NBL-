# ----------------------------------------------------------------------------------------
# üß†üì∫ YT Buddy: AI-Powered YouTube Video Analyzer
# Analyze and Summarize YouTube Videos Using LLaMA 3.2B + Streamlit
# ----------------------------------------------------------------------------------------

# This Streamlit app allows users to:
# - Enter a YouTube video URL
# - Automatically fetch the transcript using YouTubeTranscriptApi
# - Ask questions about the video content
# - Receive concise, structured answers generated by a local LLaMA 3.2B model via Ollama

# ‚úÖ Features:
# - Uses LangChain's ChatPromptTemplate for structured prompting 
#   (Prompting = the technique of designing input formats to guide LLM responses effectively)
# - Runs the Ollama LLM locally (Ollama = a tool that runs large language models like LLaMA locally or on private servers)
# - Cleans and formats transcript text for optimal model input
# - Offers pre-suggested questions for quick exploration
# - Option to format AI responses using bullet points
# - Interactive, user-friendly interface powered by Streamlit 
#   (Streamlit = an open-source Python framework to build interactive web apps easily)
# - Keeps everything on-device for data privacy and offline use

# ü¶ô The model used is LLaMA 3.2B:
# - LLaMA = Large Language Model Meta AI (a family of open-source LLMs developed by Meta)
# - 3.2B = 3.2 billion parameters (B = billion; more parameters usually mean higher capability)

# üõ†Ô∏è Supporting Tools:
# - LangChain (a framework to connect language models with external data, prompts, and chains)
# - Ollama (to run LLMs like LLaMA locally)
# - Prompting (to instruct the model on how to respond)
# - Streamlit (to build and deploy the app interface quickly)

# Ideal for educational content review, podcast summarization, or extracting insights from long videos.
# ----------------------------------------------------------------------------------------



# ----------------------------------------------------------------------------------------
# üì¶ Import necessary modules for handling prompts, using a language model,
# creating a web app, and getting YouTube transcripts
# ----------------------------------------------------------------------------------------

# This line imports the `ChatPromptTemplate` class from the `langchain_core.prompts` module.
# Syntax: from <module> import <class>
# Used for building structured prompts that guide how the language model should respond.
from langchain_core.prompts import ChatPromptTemplate  # LangChain = framework for building LLM apps
# Prompting = crafting instructions to control LLM output
# ChatPromptTemplate = allows structured message formatting (e.g., system + user roles)

# This line imports the `Ollama` class from the LangChain community integrations.
# Ollama lets us run open-source LLMs (like LLaMA) **locally** or on private infrastructure.
# Useful when you want privacy, speed, or offline capability.
from langchain_community.llms import Ollama  # Ollama = lightweight LLM runtime that integrates with LangChain

# This imports the Streamlit library using the alias `st`.
# Syntax: import <module> as <alias>
# Streamlit turns Python scripts into shareable web apps with minimal code.
import streamlit as st  # st is the common alias used for Streamlit functions

# This line imports the YouTubeTranscriptApi class.
# This module allows us to programmatically retrieve captions/transcripts from YouTube videos.
# Especially useful for summarizing, analyzing, or extracting insights from spoken content.
from youtube_transcript_api import YouTubeTranscriptApi  # Allows access to YouTube subtitles via video ID

# This line imports two functions ‚Äî `urlparse` and `parse_qs` ‚Äî from Python‚Äôs built-in `urllib.parse` module.
# `urlparse()` breaks down a URL into parts (scheme, netloc, path, query, etc.)
# `parse_qs()` parses the query string into a dictionary so you can easily extract parameters like YouTube video IDs.
# Syntax: from <module> import <function1>, <function2>
from urllib.parse import urlparse, parse_qs  # Helpful for extracting the 'v' parameter (video ID) from YouTube links


# ----------------------------------------------------------------------------------------
# ‚öôÔ∏è Page configuration for Streamlit app
# ----------------------------------------------------------------------------------------

# This line sets the layout of the Streamlit web page.
# Syntax: module.function(argument_name=value)
# In this case, the module is `st` (Streamlit), the function is `set_page_config`, and
# the keyword argument is `layout="wide"`, which expands the app horizontally across the browser window.

st.set_page_config(layout="wide")  # Sets Streamlit layout to "wide" for better use of screen space.
# Other options for layout include "centered" (default), but "wide" is better for apps showing long content like transcripts or side-by-side columns.


# ----------------------------------------------------------------------------------------
# ü§ñ Initialize the Ollama LLM with the LLaMA 3.2B model and optimized generation parameters
# ----------------------------------------------------------------------------------------

# Here we create an instance of the Ollama language model using keyword arguments.
# Syntax: variable_name = ClassName(argument1=value1, argument2=value2, ...)
# In this case, `llm` becomes the instance of the `Ollama` class, ready to generate responses.

llm = Ollama(
    model="llama3.2",     # Specifies the model name to use. Here, "llama3.2" refers to the LLaMA 3.2B model.
                          # LLaMA = Large Language Model Meta AI (developed by Meta)
                          # 3.2B = 3.2 billion parameters (B = billion), affecting its capacity and performance.

    temperature=0.1,      # Controls the randomness of the model's output.
                          # Lower values (close to 0) make the output more deterministic and focused.
                          # Higher values increase creativity but also unpredictability.

    num_ctx=2048,         # Sets the context window, i.e., the number of tokens the model can consider at once.
                          # 2048 is a good fit for LLaMA 3B models‚Äîenough to handle decent-sized transcripts.

    top_p=0.8,            # Applies top-p (nucleus) sampling during text generation.
                          # Instead of choosing the single most likely word, it samples from the smallest set of words 
                          # whose cumulative probability exceeds `top_p`. Here, 80% probability coverage is used.

    num_predict=512       # Limits the number of tokens the model is allowed to generate in its response.
                          # Prevents overly long or unnecessary output; 512 is usually enough for concise answers.
)



# ----------------------------------------------------------------------------------------
# üß† Optimized prompt template for the instruct-tuned LLaMA model
# ----------------------------------------------------------------------------------------

# This block creates a prompt template using LangChain‚Äôs ChatPromptTemplate.
# Syntax: ClassName.method_name([("role", "message"), ...])
# The `.from_messages()` method takes a list of (role, message) pairs, where roles include:
# - "system": instructions for the model‚Äôs behavior
# - "user": input that the model should respond to

prompt = ChatPromptTemplate.from_messages([
    ("system", """You are a focused AI assistant analyzing video content. Instructions:
    - Provide clear, concise answers
    - Focus on the most important information
    - If unsure, admit it
    - Use bullet points for clarity when appropriate"""),
    # System message sets the overall tone, behavior, and boundaries for the AI.
    # It ensures consistent style, tone, and answer structure.

    ("user", """Here is the video transcript:
    {content}
    
    Question: {question}
    
    Provide a clear and structured answer based on the transcript.""")
    # User message uses placeholders {content} and {question}, which will be filled dynamically at runtime.
    # This ensures flexibility in reusing the same prompt structure for different video transcripts and user queries.
])

# ----------------------------------------------------------------------------------------
# üîó Create the processing chain by combining the prompt and the model
# ----------------------------------------------------------------------------------------

# Syntax: chain = prompt | model
# The `|` operator in LangChain creates a pipeline where the output of one component
# (the prompt) becomes the input to the next (the language model).
# This `chain` now accepts a dictionary with keys `content` and `question`, and returns a model-generated response.

chain = prompt | llm  # Binds the prompt and model together into a callable chain for text generation.


st.title("üé¨ü§ñ YT Buddy: Your AI Video Companion")  # Sets the title for the Streamlit app, displaying it at the top of the page.

# ----------------------------------------------------------------------------------------
# üóÇÔ∏è Initialize session state for storing transcript content
# ----------------------------------------------------------------------------------------

# Streamlit provides `st.session_state` to maintain variables across multiple user interactions
# (like button clicks or text inputs) in the same app session.
# This is useful because Streamlit reruns the script from top to bottom with every interaction,
# but session_state helps preserve values.

# Syntax: 
# if "key" not in st.session_state:
#     st.session_state.key = default_value

# Here, we're checking if the "content" key exists in the session state.
# If not, we initialize it with an empty string ("").

if "content" not in st.session_state:
    st.session_state.content = ""  # Initializes "content" to store the YouTube transcript.
    # This helps persist the loaded transcript across app interactions (e.g., while asking questions).


# ----------------------------------------------------------------------------------------
# üßπ clean_transcript(): Clean and format transcript text for model input
# ----------------------------------------------------------------------------------------

# This function is used to clean raw YouTube transcript text before sending it to the language model.
# Syntax: 
# def function_name(parameter):
#     """docstring (optional description)"""
#     ... function body ...
#     return value

def clean_transcript(text):
    """Clean and format transcript text for model input"""

    # -------------------------------
    # 1Ô∏è‚É£ Remove unnecessary whitespace
    # -------------------------------
    # text.split()           ‚Üí splits the string into a list of words (default splits on any whitespace)
    # ' '.join(...)          ‚Üí joins those words back into a single string with one space between each
    # This effectively removes extra spaces, tabs, or newlines.

    text = ' '.join(text.split())

    # -------------------------------
    # 2Ô∏è‚É£ Remove non-verbal markers
    # -------------------------------
    # .replace(old, new)     ‚Üí replaces occurrences of `old` substring with `new` (in this case, empty string '')
    # Removes common tags found in transcripts that don't contribute to spoken meaning

    text = text.replace('[Music]', '')       # Removes background music tags
    text = text.replace('[Applause]', '')    # Removes audience reaction tags

    # -------------------------------
    # 3Ô∏è‚É£ Truncate long transcripts
    # -------------------------------
    # Most LLMs like LLaMA 3B have a token limit (context window); here we assume ~4000 characters is safe
    # Slicing syntax: text[start:end] returns a substring from index `start` to `end - 1`

    return text[:4000]  # Returns only the first 4000 characters of cleaned text to fit model's input limit


# ----------------------------------------------------------------------------------------
# üìÑ get_transcript_content(): Extract and clean transcript from a YouTube URL
# ----------------------------------------------------------------------------------------

# This function takes a YouTube video URL, extracts the video ID,
# fetches the transcript using YouTubeTranscriptApi, cleans it, and returns the result.

# Syntax: 
# def function_name(parameter):
#     ...function logic...
#     return result

def get_transcript_content(url):
    content = ""  # Initialize a variable to hold the final cleaned transcript as an empty string

    try:
        # -------------------------------
        # 1Ô∏è‚É£ Parse the URL
        # -------------------------------
        parsed_url = urlparse(url)  # Breaks the full URL into components (scheme, netloc, path, query, etc.)
        query_params = parse_qs(parsed_url.query)  # Parses query string into a dictionary format
        
        # Extract the 'v' parameter, which is the video ID in a standard YouTube URL like:
        # https://www.youtube.com/watch?v=abc123
        # query_params.get('v', [None]) ‚Üí returns a list; [0] accesses the first value or None if missing
        video_id = query_params.get('v', [None])[0]

        # -------------------------------
        # 2Ô∏è‚É£ Validate the video ID
        # -------------------------------
        if not video_id:
            st.error("Invalid YouTube URL")  # Show error message in the Streamlit app
            return content  # Exit early and return empty string if video ID is not found

        # -------------------------------
        # 3Ô∏è‚É£ Get the transcript
        # -------------------------------
        transcript_list = YouTubeTranscriptApi.get_transcript(video_id)
        # transcript_list is a list of dicts: [{'text': '...', 'start': ..., 'duration': ...}, ...]

        # Use list comprehension to join all 'text' fields into one string
        content = " ".join([t["text"] for t in transcript_list])

        # -------------------------------
        # 4Ô∏è‚É£ Clean the transcript
        # -------------------------------
        content = clean_transcript(content)  # Remove tags and trim to length limit for model input

    except Exception as e:
        # -------------------------------
        # 5Ô∏è‚É£ Handle errors gracefully
        # -------------------------------
        # Exception handling using try-except blocks ensures that unexpected issues (e.g., no captions, bad URL) 
        # don‚Äôt crash the app.
        st.error(f"Error getting transcript: {str(e)}")  # Display readable error message in the UI

    return content  # Return cleaned transcript (or empty string if there was an error)


# ----------------------------------------------------------------------------------------
# üí° SUGGESTED_QUESTIONS: Predefined queries for quick interaction
# ----------------------------------------------------------------------------------------

# This list contains suggested questions a user might ask about the video.
# It helps guide users toward asking concise, meaningful questions that work well
# with smaller LLMs like LLaMA 3.2B, which have limited context and output capacity.

# Syntax: variable_name = [item1, item2, item3, ...]
# A Python list (denoted by square brackets []) holds multiple string items.

SUGGESTED_QUESTIONS = [
    "What is the main topic covered in this video?",            # General summary prompt
    "List the key points in bullet points.",                    # Structured summary prompt
    "What are the top takeaways from this content?",            # Insight-focused prompt
    "Can you summarize the video briefly?",                     # Concise overview prompt
    "Are there any important examples or facts mentioned?",     # Specific detail prompt
]


# ----------------------------------------------------------------------------------------
# üè† main_page(): Main Streamlit UI logic for the app
# ----------------------------------------------------------------------------------------

# This function builds and displays the main web page of the Streamlit app.
# It contains the interface for entering YouTube links, loading transcripts,
# viewing the text, selecting predefined questions, and asking custom queries.

def main_page():

    # -------------------------------------
    # 1Ô∏è‚É£ Show app title and user guidance
    # -------------------------------------
    st.markdown("""
    ### üì∫ YouTube Video Analysis
    Using LLaMA 3.2B Instruct model for concise video content analysis.

    **Tips:**
    - Ask short, specific questions
    - Use bullet points option for clearer summaries
    - Keep questions focused on main content
    """)
    # st.markdown() renders Markdown-formatted text in the Streamlit app.

    # -------------------------------------
    # 2Ô∏è‚É£ Input field for YouTube URL
    # -------------------------------------
    url = st.text_input(
        "Enter YouTube URL",  # Label above the text input box
        value="https://www.youtube.com/watch?v=LWMzyfvuehA&t=1369s"  # Default value for demonstration
    )
    # st.text_input() creates a text box for user input; value sets the default text

    # -------------------------------------
    # 3Ô∏è‚É£ Create two columns for UI layout
    # -------------------------------------
    col1, col2 = st.columns([1, 1])  # Creates two equal-width columns

    with col1:
        clicked = st.button("Load Video", type="primary")  # Button to trigger loading of the transcript

    with col2:
        use_bullets = st.checkbox("Use bullet points in response", value=True)
        # Checkbox to let users decide if they want bullet point formatting in the answer

    # -------------------------------------
    # 4Ô∏è‚É£ Load transcript on button click
    # -------------------------------------
    if clicked:
        with st.spinner("Loading transcript..."):  # Shows animated spinner during processing
            content = get_transcript_content(url)  # Calls helper function to fetch and clean transcript

            if content:
                st.session_state.content = content  # Store transcript in session state to reuse later
                st.success("Loaded!")  # Show success message
            else:
                st.error("Could not load transcript")  # Show error if transcript is empty or fails

    # -------------------------------------
    # 5Ô∏è‚É£ Show transcript and Q&A interface
    # -------------------------------------
    if st.session_state.content:  # Only proceed if transcript has been successfully loaded

        col1, col2 = st.columns([4, 6])  # Split layout: 40% width for left column, 60% for right

        with col1:
            with st.expander("Video Transcript", expanded=True):  # Expandable section for showing the transcript
                st.write(st.session_state.content)  # Display the transcript text

            # Display quick-access suggested questions
            st.markdown("### Quick Questions")
            for q in SUGGESTED_QUESTIONS:
                if st.button(q):  # Render each question as a clickable button
                    if use_bullets:
                        q += " Please format as bullet points."  # Modify question if bullet formatting is requested
                    st.session_state.current_question = q  # Store selected question in session state

        with col2:
            # Text area for custom question input
            question = st.text_area(
                "Ask about the video:",
                value=getattr(st.session_state, 'current_question', "What is this video about?"),  # Default or stored question
                height=100  # Height of the input box
            )

            if question:
                with st.spinner("Analyzing..."):  # Show spinner while processing
                    try:
                        # If bullet formatting is requested but not already in the question, append it
                        if use_bullets and "bullet points" not in question.lower():
                            question += " Please format as bullet points."

                        # Call the LLM chain with transcript and user question
                        response = chain.invoke({
                            "content": st.session_state.content,
                            "question": question
                        })

                        with st.container(border=True):  # Display response inside a bordered container
                            st.markdown("### Analysis:")
                            st.write(response)

                    except Exception as e:
                        # If an error occurs (e.g., Ollama not running), display helpful messages
                        st.error(f"Error: {str(e)}")
                        st.info("Make sure Ollama is running with the correct model")


# ----------------------------------------------------------------------------------------
# üöÄ Entry point for the Streamlit app
# ----------------------------------------------------------------------------------------

# This block checks if the script is being run directly (not imported as a module).
# Syntax: if __name__ == "__main__":
# In Python, the built-in variable `__name__` is set to "__main__" only when the script is run directly.

# This pattern is useful to:
# ‚úÖ Ensure certain code only runs when this file is the entry point
# ‚úÖ Prevent code from executing during imports (e.g., in testing or other scripts)

if __name__ == "__main__":
    main_page()  # Calls the function that builds the Streamlit app interface

# ----------------------------------------------------------------------------------------
# üõ†Ô∏è SETUP INSTRUCTIONS: How to Run the YouTube Video Analyzer App
# All steps provided as comments for reference within your code.
# ----------------------------------------------------------------------------------------

# 1Ô∏è‚É£ Step 1: Download and Install Ollama
# ---------------------------------------
# Ollama is required to run the LLaMA 3.2B model locally on your machine.
# Visit the official website and install Ollama for your operating system:
# üëâ https://ollama.com/

# After installation, verify it's working by running this command in your terminal:
# ollama run llama3
# (Note: The first time you run this, it will download the model, which may take some time.)

# 2Ô∏è‚É£ Step 2: (Optional but recommended) Create and Activate a Virtual Environment
# --------------------------------------------------------------------------------
# This keeps your dependencies isolated and avoids version conflicts.
# In your terminal or command prompt, run:

# python -m venv ytapp-env
# source ytapp-env/bin/activate        # On macOS/Linux
# ytapp-env\Scripts\activate           # On Windows

# 3Ô∏è‚É£ Step 3: Install Required Python Packages
# -------------------------------------------
# Use pip to install all necessary packages:

# pip install streamlit langchain langchain-community youtube-transcript-api

# 4Ô∏è‚É£ Step 4: Save the Application Code
# ------------------------------------
# Save your full app code into a file named something like:
# app.py

# 5Ô∏è‚É£ Step 5: Run the App with Streamlit
# -------------------------------------
# Make sure the Ollama service is running (from Step 1), then launch the app with:

# streamlit run app.py

# This will start the Streamlit app and open it in your default browser at:
# http://localhost:8501

# ‚úÖ You‚Äôre now ready to:
# - Paste a YouTube video link
# - Load and clean its transcript
# - Ask the model focused questions
# - Get clear, structured answers from LLaMA 3.2B running locally via Ollama

# ----------------------------------------------------------------------------------------
# Happy Building! üé¨ü§ñ
# ----------------------------------------------------------------------------------------
